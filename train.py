# -*- coding: utf-8 -*-
"""project7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HFdEkyJ80HHewr6PI0JqUWoQ0sLAjJCC
"""

#from google.colab import drive
#drive.mount('/content/drive')

#!pip install split-folders

import os
import pathlib
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam

import splitfolders

input_folder = 'Plant_Seed_Data'
output_folder = 'Data_Split'

splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.8, .2, .0))

import glob

train_length = 0
val_length = 0

for name in glob.glob('Data_Split/train/*'):
  train_length += len(glob.glob(name+'/*.png'))

for name in glob.glob('Data_Split/val/*'):
  val_length += len(glob.glob(name+'/*.png'))

print(train_length,val_length)

batch_size = 32
img_height = 120
img_width = 120

data_dir_train = 'Data_Split/train'
data_dir_val = 'Data_Split/val'

labels = sorted(os.listdir(data_dir_train))
print(labels)

count = []

for i in labels:
  count.append((len(os.listdir(os.path.join(data_dir_train,i)))))

print(count)

import cv2

def flip_image(image):
    return cv2.flip(image, 1)  # horizontal flip

def rotate_image(image, angle):
    h, w = image.shape[:2]
    center = (w / 2, h / 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    return cv2.warpAffine(image, M, (w, h))

def scale_image(image, scale):
    h, w = image.shape[:2]
    return cv2.resize(image, (int(w * scale), int(h * scale)))

def augment_image(image):
    augmentations = []
    augmentations.append(flip_image(image))
    augmentations.append(rotate_image(image, angle=25))
    augmentations.append(rotate_image(image, angle=-25))
    augmentations.append(scale_image(image, scale=1.2))
    augmentations.append(scale_image(image, scale=0.8))
    return augmentations

def augment_and_save_images(input_dir):
    for class_dir in os.listdir(input_dir):
        class_path = os.path.join(input_dir, class_dir)
        if not os.path.isdir(class_path):
            continue

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            image = cv2.imread(img_path)
            if image is None:
                continue

            augmented_images = augment_image(image)
            for i, aug_img in enumerate(augmented_images):
                output_img_name = f"{os.path.splitext(img_name)[0]}_aug_{i}{os.path.splitext(img_name)[1]}"
                output_img_path = os.path.join(class_path, output_img_name)
                cv2.imwrite(output_img_path, aug_img)

input_directory = data_dir_train

augment_and_save_images(input_directory)

count_aug = []

for i in labels:
  count_aug.append((len(os.listdir(os.path.join(data_dir_train,i)))))

print(count_aug)

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir_train,
  seed=123, label_mode='categorical',
  validation_split = 0.0,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir_train,
  seed=123, label_mode='categorical',
  validation_split = 0.0,
  image_size=(img_height, img_width),
  batch_size=batch_size)

input_shape = (120,120,3)
num_classes = 12

model = Sequential()
model.add(tf.keras.layers.Rescaling(1./255, offset=0.0))
model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape, padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(32, kernel_size=(3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.10))

model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.10))

model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(128, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.10))

model.add(Flatten())
model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.25))
model.add(Dense(num_classes))
model.add(Activation('softmax'))

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy', 'precision', 'recall'])

epochs = 20
batch_size = 32
history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, batch_size=batch_size)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

model.save('model.h5')